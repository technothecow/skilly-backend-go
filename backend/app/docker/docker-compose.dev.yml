services:
  app:
    build:
      context: .. # Path to the directory containing the Dockerfile
    environment:
      # --- Configuration for your Go App ---
      # Example environment variables your app might need to connect to other services
      # MONGODB_URI: mongodb://mongo:27017 # Use service name 'mongo' and default port
      JWT_SECRET_KEY: secretsecretsecretsecretsecretsecret
      MINIO_ENDPOINT: s3.localhost # Use service name 'minio' and its API port
      MINIO_ACCESS_KEY: minioadmin # MUST match MINIO_ROOT_USER below
      MINIO_SECRET_KEY: minioadmin # MUST match MINIO_ROOT_PASSWORD below
      MINIO_USE_SSL: "false" # Connect to MinIO within Docker network without SSL
      MINIO_BUCKET_NAME: skilly # Default bucket name your app might use
      KAFKA_BROKERS: kafka:9092
    depends_on:
      - mongo # Wait for mongo to start (doesn't guarantee readiness, just container start)
      - minio # Wait for minio to start
      - kafka # Wait for kafka to start
    networks:
      - app-network # Connect to the custom network
    restart: unless-stopped # Restart policy
    extra_hosts:
      - "s3.localhost:host-gateway"

  # MongoDB Service
  mongo:
    image: mongo:8.0.9 # Use the official MongoDB image (consider pinning a version e.g., mongo:6.0)
    ports:
      - "27017:27017" # Optional: Map host port for direct access (debugging)
    volumes:
      - mongo_data:/data/db # Persist database data using a named volume
    networks:
      - app-network
    restart: unless-stopped

  # MinIO (S3 Compatible Storage) Service
  minio:
    build:
      context: ../minio
    environment:
      # --- MinIO Configuration ---
      # IMPORTANT: Change these default credentials for production!
      MINIO_ROOT_USER: minioadmin
      MINIO_ROOT_PASSWORD: minioadmin
      MINIO_NOTIFY_KAFKA_ENABLE_kafka1: on
      MINIO_NOTIFY_KAFKA_ID_kafka1: "kafka1"
      MINIO_NOTIFY_KAFKA_BROKERS_kafka1: "kafka:9092"
      MINIO_NOTIFY_KAFKA_TOPIC_kafka1: "minio-events"
      MINIO_NOTIFY_KAFKA_QUEUE_DIR_kafka1: "/opt/minio/events-queue"
    volumes:
      - minio_data:/data # Persist bucket data using a named volume
    entrypoint: /usr/local/bin/minio-entrypoint.sh
    networks:
      - app-network
    restart: unless-stopped

  nginx:
    image: nginx:alpine
    ports:
      - "80:80" # Host's port 80 maps to Nginx container's port 80
    volumes:
      - ../nginx/nginx.dev.conf:/etc/nginx/nginx.conf:ro # Mount your Nginx config
    depends_on:
      - app
    networks:
      - app-network
    restart: unless-stopped

  kafka:
    image: confluentinc/cp-kafka:7.6.1 # Use a KRaft-compatible version
    environment:
      # KRaft settings
      KAFKA_NODE_ID: 1
      KAFKA_PROCESS_ROLES: "broker,controller" # Combined roles for single node
      CLUSTER_ID: "tEx0PJCXR5mMLGdVV9oYIg"
      KAFKA_CONTROLLER_QUORUM_VOTERS: "1@kafka:9093" # Format: node_id@host:port

      # Listeners
      # INTERNAL: For communication within the Docker network (e.g., Kafka UI <-> Kafka, Broker <-> Controller on same node)
      # EXTERNAL: For communication from your host machine (e.g., your Go app <-> Kafka)
      # CONTROLLER: For KRaft controller communication
      KAFKA_LISTENERS: "INTERNAL://0.0.0.0:9092,CONTROLLER://0.0.0.0:9093"
      KAFKA_ADVERTISED_LISTENERS: "INTERNAL://kafka:9092"
      KAFKA_CONTROLLER_LISTENER_NAMES: "CONTROLLER"
      KAFKA_LISTENER_SECURITY_PROTOCOL_MAP: "INTERNAL:PLAINTEXT,EXTERNAL:PLAINTEXT,CONTROLLER:PLAINTEXT"
      KAFKA_INTER_BROKER_LISTENER_NAME: "INTERNAL" # Still used for broker listener name

      # Topic settings for single-node cluster (still relevant)
      KAFKA_OFFSETS_TOPIC_REPLICATION_FACTOR: 1
      KAFKA_GROUP_INITIAL_REBALANCE_DELAY_MS: 0
      KAFKA_TRANSACTION_STATE_LOG_MIN_ISR: 1
      KAFKA_TRANSACTION_STATE_LOG_REPLICATION_FACTOR: 1
      # Optional: Auto create topics
      KAFKA_AUTO_CREATE_TOPICS_ENABLE: "true"

      # KRaft specific log dirs (metadata will be stored here too)
      # The default /var/lib/kafka/data usually works fine.
      # KAFKA_LOG_DIRS: '/var/lib/kafka/data/kraft-combined'

    volumes:
      - kafka_data:/var/lib/kafka/data # Persist Kafka data (including KRaft metadata)
    networks:
      - app-network
    healthcheck:
      # The healthcheck connects as a client, so it uses a client port
      test: ["CMD-SHELL", "kafka-topics --bootstrap-server kafka:9092 --list || exit 1"]
      interval: 30s
      timeout: 10s
      retries: 5
      start_period: 20s # Give Kafka more time to start in KRaft mode as it needs to format/elect controller

  kafka-ui:
    image: provectuslabs/kafka-ui:latest
    depends_on:
      kafka:
        condition: service_healthy # Wait for Kafka to be healthy
    ports:
      - "8080:8080" # Kafka UI web interface
    environment:
      KAFKA_CLUSTERS_0_NAME: "Local KRaft Kafka"
      # Kafka UI connects to the broker using its INTERNAL client listener
      KAFKA_CLUSTERS_0_BOOTSTRAPSERVERS: "kafka:9092"
      # No Zookeeper for KRaft
      DYNAMIC_CONFIG_ENABLED: "true"
    networks:
      - app-network
    restart: always


# Define named volumes for persistent storage
volumes:
  mongo_data: {} # Docker will manage this volume
  minio_data: {} # Docker will manage this volume
  kafka_data: {} # Docker will manage this volume

# Define custom network for service communication
networks:
  app-network:
    driver: bridge # Use the default bridge driver
